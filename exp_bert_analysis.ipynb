{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8f4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03886966",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ace618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb48b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-cased\"\n",
    "bert_model = BertModel.from_pretrained(model_name)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "e = bert_model.eval()\n",
    "z = bert_model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e610c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"preprocess_docs.xlsx\"\n",
    "df = pd.read_excel(file_name, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71c2c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 238\n",
      "1 137\n",
      "2 156\n",
      "3 250\n",
      "4 163\n",
      "5 212\n",
      "6 125\n",
      "7 124\n",
      "8 195\n",
      "9 180\n",
      "10 165\n",
      "11 116\n",
      "12 182\n",
      "13 165\n",
      "14 234\n",
      "15 90\n",
      "16 132\n",
      "17 381\n",
      "18 152\n",
      "19 143\n",
      "20 204\n",
      "21 237\n",
      "22 184\n",
      "23 160\n",
      "24 202\n",
      "25 216\n",
      "26 207\n",
      "27 140\n",
      "28 126\n",
      "29 328\n",
      "30 161\n",
      "31 200\n",
      "32 148\n",
      "33 196\n",
      "34 162\n",
      "35 90\n",
      "36 293\n",
      "37 235\n",
      "38 135\n",
      "39 150\n",
      "40 211\n",
      "41 140\n",
      "42 197\n",
      "43 114\n",
      "44 161\n",
      "45 173\n",
      "46 172\n",
      "47 166\n",
      "48 209\n",
      "49 143\n",
      "50 175\n",
      "51 160\n",
      "52 128\n",
      "53 160\n",
      "54 185\n",
      "55 123\n",
      "56 193\n",
      "57 222\n",
      "58 230\n",
      "59 175\n",
      "60 188\n",
      "61 166\n",
      "62 201\n",
      "63 209\n",
      "64 170\n",
      "65 176\n",
      "66 198\n",
      "67 244\n",
      "68 178\n",
      "69 181\n",
      "70 139\n",
      "71 170\n",
      "72 180\n",
      "73 130\n",
      "74 194\n",
      "75 202\n",
      "76 130\n",
      "77 189\n",
      "78 160\n",
      "79 172\n",
      "80 206\n",
      "81 112\n",
      "82 248\n",
      "83 310\n",
      "84 120\n",
      "85 141\n",
      "86 205\n",
      "87 166\n",
      "88 201\n",
      "89 129\n",
      "90 265\n",
      "91 116\n",
      "92 113\n",
      "93 194\n",
      "94 161\n",
      "95 140\n",
      "96 230\n",
      "97 202\n",
      "98 109\n",
      "99 136\n",
      "100 223\n",
      "101 116\n",
      "102 150\n",
      "103 195\n",
      "104 125\n",
      "105 102\n",
      "106 154\n",
      "107 321\n",
      "108 101\n",
      "109 225\n",
      "110 111\n",
      "111 146\n",
      "112 208\n",
      "113 79\n",
      "114 82\n",
      "115 149\n",
      "116 181\n",
      "117 145\n",
      "118 182\n",
      "119 140\n",
      "120 111\n",
      "121 128\n",
      "122 111\n",
      "123 159\n",
      "124 127\n",
      "125 156\n",
      "126 165\n",
      "127 155\n",
      "128 204\n",
      "129 200\n",
      "130 136\n",
      "131 145\n",
      "132 132\n",
      "133 126\n",
      "134 33\n",
      "135 236\n",
      "136 140\n",
      "137 117\n",
      "138 106\n",
      "139 7\n",
      "140 113\n",
      "141 4\n",
      "142 206\n",
      "143 154\n",
      "144 194\n",
      "145 197\n",
      "146 74\n",
      "147 172\n",
      "148 132\n",
      "149 173\n",
      "150 147\n",
      "151 198\n",
      "152 140\n",
      "153 87\n",
      "154 144\n",
      "155 160\n",
      "156 129\n",
      "157 241\n",
      "158 217\n",
      "159 239\n",
      "160 155\n",
      "161 153\n",
      "162 193\n",
      "163 97\n",
      "164 158\n",
      "165 84\n",
      "166 139\n",
      "167 120\n",
      "168 107\n",
      "169 235\n",
      "170 357\n",
      "171 164\n",
      "172 189\n",
      "173 162\n",
      "174 156\n",
      "175 126\n",
      "176 99\n",
      "177 107\n",
      "178 131\n",
      "179 61\n",
      "180 99\n",
      "181 78\n",
      "182 85\n",
      "183 115\n",
      "184 69\n",
      "185 108\n",
      "186 75\n",
      "187 135\n",
      "188 182\n",
      "CPU times: total: 6min 21s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "token_embd = {}\n",
    "for ix in df.index:\n",
    "  preprocess = eval(df.loc[ix][\"preprocess\"])\n",
    "  doc_clean = preprocess[\"doc_clean\"]\n",
    "  matching = preprocess[\"matching\"]\n",
    "  uni_stop = max([i for i, v in enumerate(matching) if type(v[0]) == int])+1\n",
    "  doc = \" \".join(doc_clean[:uni_stop])\n",
    "  label = df.loc[ix][\"label\"]\n",
    "\n",
    "  tokens = bert_tokenizer.tokenize(doc)\n",
    "  if len(tokens) > 512:\n",
    "    tokens1 = tokens[:512]\n",
    "    tokens2 = tokens[512:512*2]\n",
    "\n",
    "    tokens_ids1 = bert_tokenizer.convert_tokens_to_ids(tokens1)\n",
    "    tokens_ids1_tensor = torch.tensor(tokens_ids1)\n",
    "    attn_mask1 = (tokens_ids1_tensor != 1).long() # [PAD] => 1\n",
    "\n",
    "    print(ix, len(tokens_ids1))\n",
    "\n",
    "    cont1 = bert_model(tokens_ids1_tensor.unsqueeze(0), attention_mask=attn_mask1.unsqueeze(0))\n",
    "\n",
    "    token_embd_per_doc = []\n",
    "    for i, token in enumerate(tokens1):\n",
    "      embd = cont1.last_hidden_state[0][i].detach().numpy()\n",
    "      token_embd_per_doc.append(embd)\n",
    "\n",
    "    tokens_ids2 = bert_tokenizer.convert_tokens_to_ids(tokens2)\n",
    "    tokens_ids2_tensor = torch.tensor(tokens_ids2)\n",
    "    attn_mask2 = (tokens_ids2_tensor != 1).long() # [PAD] => 1\n",
    "\n",
    "    print(ix, len(tokens_ids2))\n",
    "\n",
    "    cont2 = bert_model(tokens_ids2_tensor.unsqueeze(0), attention_mask=attn_mask2.unsqueeze(0))\n",
    "\n",
    "    for i, token in enumerate(tokens2):\n",
    "      embd = cont2.last_hidden_state[0][i].detach().numpy()\n",
    "      token_embd_per_doc.append(embd)\n",
    "\n",
    "    token_embd[label] = (tokens, token_embd_per_doc)\n",
    "    \n",
    "  else:\n",
    "    tokens_ids = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
    "    tokens_ids_tensor = torch.tensor(tokens_ids)\n",
    "    attn_mask = (tokens_ids_tensor != 1).long() # [PAD] => 1\n",
    "\n",
    "    print(ix, len(tokens_ids))\n",
    "\n",
    "    cont = bert_model(tokens_ids_tensor.unsqueeze(0), attention_mask=attn_mask.unsqueeze(0))\n",
    "\n",
    "\n",
    "    token_embd_per_doc = []\n",
    "    for i, token in enumerate(tokens):\n",
    "      embd = cont.last_hidden_state[0][i].detach().numpy()\n",
    "      token_embd_per_doc.append(embd)\n",
    "\n",
    "    token_embd[label] = (tokens, token_embd_per_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "28fbba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(token_embd, open(\"token_embd.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95c93621",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_graph = {df.loc[ix][\"label\"]: df.loc[ix][\"cluster\"] for ix in df.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e79c7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 87.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_token_embd = {}\n",
    "for label in token_embd.keys():\n",
    "    tokens, token_embd_per_doc = token_embd[label]\n",
    "\n",
    "    new_tokens = []\n",
    "    new_token_embd_per_doc = []\n",
    "\n",
    "    token_embd_i = token_embd_per_doc[0]\n",
    "    token = tokens[0]\n",
    "    lenght = 1\n",
    "    for i in range(1, len(tokens)):\n",
    "        token_i = tokens[i]\n",
    "        if token_i[:2] == \"##\":\n",
    "            lenght += 1\n",
    "            token_embd_i += token_embd_per_doc[i]\n",
    "            token += token_i[2:]\n",
    "        else:\n",
    "            token_embd_i = token_embd_i / lenght\n",
    "            new_token_embd_per_doc.append(token_embd_i)\n",
    "            new_tokens.append(token)\n",
    "\n",
    "            lenght = 1\n",
    "            token_embd_i = token_embd_per_doc[i]\n",
    "            token = token_i\n",
    "    new_token_embd[label] = (new_tokens, new_token_embd_per_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "797dd9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_matrix = {}\n",
    "count_term = {}\n",
    "cluster_id = 1\n",
    "for label, (tokens, token_embd_per_doc) in new_token_embd.items():\n",
    "    if cluster_graph[label] == cluster_id:\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token not in term_matrix.keys():\n",
    "                term_matrix[token] = np.zeros(768)\n",
    "                count_term[token] = 0\n",
    "            term_matrix[token] += token_embd_per_doc[i]\n",
    "            count_term[token] += 1\n",
    "term_matrix = {k: v / count_term[k] for k, v in term_matrix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "018f5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = pd.DataFrame(term_matrix).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9eb79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6280671",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans =  KMeans(n_clusters=6, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e5271d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=6, random_state=2022)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f70ba02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>0.167816</td>\n",
       "      <td>-0.520817</td>\n",
       "      <td>0.692566</td>\n",
       "      <td>-0.205275</td>\n",
       "      <td>0.369287</td>\n",
       "      <td>0.235023</td>\n",
       "      <td>-0.521668</td>\n",
       "      <td>0.535237</td>\n",
       "      <td>0.769653</td>\n",
       "      <td>0.163537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207278</td>\n",
       "      <td>0.346287</td>\n",
       "      <td>-0.331832</td>\n",
       "      <td>0.261883</td>\n",
       "      <td>-0.232969</td>\n",
       "      <td>-0.492360</td>\n",
       "      <td>-0.213416</td>\n",
       "      <td>-1.025132</td>\n",
       "      <td>0.204038</td>\n",
       "      <td>0.253584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learn</th>\n",
       "      <td>0.385292</td>\n",
       "      <td>-0.763111</td>\n",
       "      <td>0.686116</td>\n",
       "      <td>-0.286982</td>\n",
       "      <td>0.180673</td>\n",
       "      <td>0.072173</td>\n",
       "      <td>-0.328540</td>\n",
       "      <td>0.614519</td>\n",
       "      <td>0.800157</td>\n",
       "      <td>0.168622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170324</td>\n",
       "      <td>0.460309</td>\n",
       "      <td>-0.363158</td>\n",
       "      <td>0.397351</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>-0.599525</td>\n",
       "      <td>-0.288070</td>\n",
       "      <td>-0.657134</td>\n",
       "      <td>0.269817</td>\n",
       "      <td>0.321025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>implicit</th>\n",
       "      <td>0.197968</td>\n",
       "      <td>-0.484868</td>\n",
       "      <td>0.369245</td>\n",
       "      <td>-0.003862</td>\n",
       "      <td>0.354030</td>\n",
       "      <td>-0.085893</td>\n",
       "      <td>-0.587141</td>\n",
       "      <td>0.796825</td>\n",
       "      <td>1.197275</td>\n",
       "      <td>0.042180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069545</td>\n",
       "      <td>0.540698</td>\n",
       "      <td>-0.429407</td>\n",
       "      <td>-0.211454</td>\n",
       "      <td>0.153676</td>\n",
       "      <td>-0.408632</td>\n",
       "      <td>0.034845</td>\n",
       "      <td>-0.626570</td>\n",
       "      <td>0.292982</td>\n",
       "      <td>0.455436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explicit</th>\n",
       "      <td>0.197058</td>\n",
       "      <td>-0.593117</td>\n",
       "      <td>0.746997</td>\n",
       "      <td>0.024799</td>\n",
       "      <td>0.151934</td>\n",
       "      <td>0.039749</td>\n",
       "      <td>-0.458751</td>\n",
       "      <td>0.434262</td>\n",
       "      <td>1.052656</td>\n",
       "      <td>-0.032281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.555597</td>\n",
       "      <td>0.553590</td>\n",
       "      <td>-0.638588</td>\n",
       "      <td>0.104476</td>\n",
       "      <td>-0.023907</td>\n",
       "      <td>-0.385238</td>\n",
       "      <td>0.104398</td>\n",
       "      <td>-0.845130</td>\n",
       "      <td>0.315902</td>\n",
       "      <td>0.062396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non</th>\n",
       "      <td>0.327843</td>\n",
       "      <td>-0.650699</td>\n",
       "      <td>0.397550</td>\n",
       "      <td>0.037959</td>\n",
       "      <td>0.082697</td>\n",
       "      <td>-0.187926</td>\n",
       "      <td>-0.602387</td>\n",
       "      <td>0.733930</td>\n",
       "      <td>0.941444</td>\n",
       "      <td>0.092892</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198557</td>\n",
       "      <td>0.267545</td>\n",
       "      <td>-0.785607</td>\n",
       "      <td>0.144077</td>\n",
       "      <td>-0.299918</td>\n",
       "      <td>-0.359611</td>\n",
       "      <td>0.088504</td>\n",
       "      <td>-0.612101</td>\n",
       "      <td>0.130824</td>\n",
       "      <td>0.399633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capture</th>\n",
       "      <td>0.392429</td>\n",
       "      <td>-0.548473</td>\n",
       "      <td>0.499759</td>\n",
       "      <td>-0.135191</td>\n",
       "      <td>-0.199769</td>\n",
       "      <td>-0.343124</td>\n",
       "      <td>-0.297043</td>\n",
       "      <td>0.192482</td>\n",
       "      <td>0.584212</td>\n",
       "      <td>-0.064458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046630</td>\n",
       "      <td>0.106532</td>\n",
       "      <td>-0.376058</td>\n",
       "      <td>-0.199232</td>\n",
       "      <td>-0.358138</td>\n",
       "      <td>-0.607307</td>\n",
       "      <td>-0.661267</td>\n",
       "      <td>-0.566535</td>\n",
       "      <td>0.047974</td>\n",
       "      <td>0.313740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inappropriateness</th>\n",
       "      <td>0.271552</td>\n",
       "      <td>-0.096745</td>\n",
       "      <td>0.069562</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>-0.161574</td>\n",
       "      <td>-0.614043</td>\n",
       "      <td>-0.125938</td>\n",
       "      <td>0.510729</td>\n",
       "      <td>0.364671</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211386</td>\n",
       "      <td>0.241241</td>\n",
       "      <td>-0.543218</td>\n",
       "      <td>-0.157115</td>\n",
       "      <td>-0.411815</td>\n",
       "      <td>-0.646144</td>\n",
       "      <td>-0.094903</td>\n",
       "      <td>-0.640485</td>\n",
       "      <td>-0.008809</td>\n",
       "      <td>0.149886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seriousness</th>\n",
       "      <td>0.616778</td>\n",
       "      <td>-0.003403</td>\n",
       "      <td>0.231534</td>\n",
       "      <td>0.238645</td>\n",
       "      <td>-0.123085</td>\n",
       "      <td>-0.988227</td>\n",
       "      <td>-0.315537</td>\n",
       "      <td>0.838340</td>\n",
       "      <td>0.607151</td>\n",
       "      <td>-0.266208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.309763</td>\n",
       "      <td>-0.163556</td>\n",
       "      <td>-0.284659</td>\n",
       "      <td>0.055678</td>\n",
       "      <td>-0.722849</td>\n",
       "      <td>-0.618821</td>\n",
       "      <td>-0.155228</td>\n",
       "      <td>-0.596301</td>\n",
       "      <td>0.440540</td>\n",
       "      <td>-0.062036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine</th>\n",
       "      <td>0.469318</td>\n",
       "      <td>-0.205466</td>\n",
       "      <td>0.460433</td>\n",
       "      <td>-0.260546</td>\n",
       "      <td>-0.135559</td>\n",
       "      <td>-0.748442</td>\n",
       "      <td>-0.265260</td>\n",
       "      <td>0.612635</td>\n",
       "      <td>0.489478</td>\n",
       "      <td>-0.348593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081604</td>\n",
       "      <td>0.364843</td>\n",
       "      <td>-0.322390</td>\n",
       "      <td>0.573405</td>\n",
       "      <td>-0.560411</td>\n",
       "      <td>-0.559085</td>\n",
       "      <td>-0.029280</td>\n",
       "      <td>-0.407410</td>\n",
       "      <td>0.661643</td>\n",
       "      <td>-0.049528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abolition</th>\n",
       "      <td>-0.088826</td>\n",
       "      <td>-0.548781</td>\n",
       "      <td>0.111046</td>\n",
       "      <td>-0.249358</td>\n",
       "      <td>-0.187613</td>\n",
       "      <td>-0.107864</td>\n",
       "      <td>0.154575</td>\n",
       "      <td>0.377897</td>\n",
       "      <td>0.476199</td>\n",
       "      <td>0.006455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440094</td>\n",
       "      <td>0.134643</td>\n",
       "      <td>-0.522438</td>\n",
       "      <td>0.330618</td>\n",
       "      <td>-0.330875</td>\n",
       "      <td>-0.834352</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.414137</td>\n",
       "      <td>-0.147227</td>\n",
       "      <td>0.210156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2114 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5    \\\n",
       "student            0.167816 -0.520817  0.692566 -0.205275  0.369287  0.235023   \n",
       "learn              0.385292 -0.763111  0.686116 -0.286982  0.180673  0.072173   \n",
       "implicit           0.197968 -0.484868  0.369245 -0.003862  0.354030 -0.085893   \n",
       "explicit           0.197058 -0.593117  0.746997  0.024799  0.151934  0.039749   \n",
       "non                0.327843 -0.650699  0.397550  0.037959  0.082697 -0.187926   \n",
       "...                     ...       ...       ...       ...       ...       ...   \n",
       "capture            0.392429 -0.548473  0.499759 -0.135191 -0.199769 -0.343124   \n",
       "inappropriateness  0.271552 -0.096745  0.069562  0.012946 -0.161574 -0.614043   \n",
       "seriousness        0.616778 -0.003403  0.231534  0.238645 -0.123085 -0.988227   \n",
       "genuine            0.469318 -0.205466  0.460433 -0.260546 -0.135559 -0.748442   \n",
       "abolition         -0.088826 -0.548781  0.111046 -0.249358 -0.187613 -0.107864   \n",
       "\n",
       "                        6         7         8         9    ...       758  \\\n",
       "student           -0.521668  0.535237  0.769653  0.163537  ... -0.207278   \n",
       "learn             -0.328540  0.614519  0.800157  0.168622  ... -0.170324   \n",
       "implicit          -0.587141  0.796825  1.197275  0.042180  ... -0.069545   \n",
       "explicit          -0.458751  0.434262  1.052656 -0.032281  ... -0.555597   \n",
       "non               -0.602387  0.733930  0.941444  0.092892  ... -0.198557   \n",
       "...                     ...       ...       ...       ...  ...       ...   \n",
       "capture           -0.297043  0.192482  0.584212 -0.064458  ...  0.046630   \n",
       "inappropriateness -0.125938  0.510729  0.364671  0.064200  ... -0.211386   \n",
       "seriousness       -0.315537  0.838340  0.607151 -0.266208  ... -0.309763   \n",
       "genuine           -0.265260  0.612635  0.489478 -0.348593  ...  0.081604   \n",
       "abolition          0.154575  0.377897  0.476199  0.006455  ... -0.440094   \n",
       "\n",
       "                        759       760       761       762       763       764  \\\n",
       "student            0.346287 -0.331832  0.261883 -0.232969 -0.492360 -0.213416   \n",
       "learn              0.460309 -0.363158  0.397351  0.037847 -0.599525 -0.288070   \n",
       "implicit           0.540698 -0.429407 -0.211454  0.153676 -0.408632  0.034845   \n",
       "explicit           0.553590 -0.638588  0.104476 -0.023907 -0.385238  0.104398   \n",
       "non                0.267545 -0.785607  0.144077 -0.299918 -0.359611  0.088504   \n",
       "...                     ...       ...       ...       ...       ...       ...   \n",
       "capture            0.106532 -0.376058 -0.199232 -0.358138 -0.607307 -0.661267   \n",
       "inappropriateness  0.241241 -0.543218 -0.157115 -0.411815 -0.646144 -0.094903   \n",
       "seriousness       -0.163556 -0.284659  0.055678 -0.722849 -0.618821 -0.155228   \n",
       "genuine            0.364843 -0.322390  0.573405 -0.560411 -0.559085 -0.029280   \n",
       "abolition          0.134643 -0.522438  0.330618 -0.330875 -0.834352 -0.024120   \n",
       "\n",
       "                        765       766       767  \n",
       "student           -1.025132  0.204038  0.253584  \n",
       "learn             -0.657134  0.269817  0.321025  \n",
       "implicit          -0.626570  0.292982  0.455436  \n",
       "explicit          -0.845130  0.315902  0.062396  \n",
       "non               -0.612101  0.130824  0.399633  \n",
       "...                     ...       ...       ...  \n",
       "capture           -0.566535  0.047974  0.313740  \n",
       "inappropriateness -0.640485 -0.008809  0.149886  \n",
       "seriousness       -0.596301  0.440540 -0.062036  \n",
       "genuine           -0.407410  0.661643 -0.049528  \n",
       "abolition         -0.414137 -0.147227  0.210156  \n",
       "\n",
       "[2114 rows x 768 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b4d56f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22558941, -0.56518902,  0.47662052, ..., -0.78617984,\n",
       "         0.12220512,  0.327748  ],\n",
       "       [ 0.20553102, -0.45288328,  0.41846354, ..., -0.61437471,\n",
       "         0.29275487,  0.38887632],\n",
       "       [ 0.27462403, -0.55606979,  0.19939457, ..., -0.66931545,\n",
       "        -0.00711895,  0.18437753],\n",
       "       [ 0.22037362, -0.55001439,  0.45040705, ..., -0.84628363,\n",
       "         0.23261873,  0.42586109],\n",
       "       [ 0.25656757, -0.53324803,  0.37242352, ..., -0.7840618 ,\n",
       "         0.285144  ,  0.27965373],\n",
       "       [ 0.21208382, -0.52290966,  0.30927924, ..., -0.38559376,\n",
       "        -0.01507883,  0.35281948]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = kmeans.predict(terms)\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c878640b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.532549979170748"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid = centroids[0]\n",
    "dist = np.linalg.norm(centroid - embd)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6e99f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 219 ms\n",
      "Wall time: 199 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dists = {}\n",
    "for term in terms.index:\n",
    "    dists[term] = []\n",
    "    embd = terms.loc[term].values\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        dist = np.linalg.norm(centroid - embd)\n",
    "        dists[term].append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0e6f0343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>4.461106</td>\n",
       "      <td>5.245509</td>\n",
       "      <td>6.531579</td>\n",
       "      <td>3.803008</td>\n",
       "      <td>4.376983</td>\n",
       "      <td>6.363828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learn</th>\n",
       "      <td>4.556132</td>\n",
       "      <td>4.809060</td>\n",
       "      <td>6.977041</td>\n",
       "      <td>3.949124</td>\n",
       "      <td>4.278583</td>\n",
       "      <td>6.672489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>implicit</th>\n",
       "      <td>6.331229</td>\n",
       "      <td>7.343241</td>\n",
       "      <td>7.000492</td>\n",
       "      <td>6.470834</td>\n",
       "      <td>6.698545</td>\n",
       "      <td>7.979024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explicit</th>\n",
       "      <td>5.783002</td>\n",
       "      <td>6.684466</td>\n",
       "      <td>8.166710</td>\n",
       "      <td>6.198750</td>\n",
       "      <td>6.228590</td>\n",
       "      <td>8.303774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non</th>\n",
       "      <td>4.376479</td>\n",
       "      <td>5.877950</td>\n",
       "      <td>7.075219</td>\n",
       "      <td>5.137199</td>\n",
       "      <td>5.576512</td>\n",
       "      <td>6.939883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capture</th>\n",
       "      <td>7.165847</td>\n",
       "      <td>6.914288</td>\n",
       "      <td>9.295683</td>\n",
       "      <td>7.328633</td>\n",
       "      <td>7.827425</td>\n",
       "      <td>8.653174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inappropriateness</th>\n",
       "      <td>7.548584</td>\n",
       "      <td>7.927481</td>\n",
       "      <td>8.994511</td>\n",
       "      <td>8.002313</td>\n",
       "      <td>8.295702</td>\n",
       "      <td>9.165384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seriousness</th>\n",
       "      <td>7.954154</td>\n",
       "      <td>8.521012</td>\n",
       "      <td>9.016651</td>\n",
       "      <td>8.596704</td>\n",
       "      <td>8.011523</td>\n",
       "      <td>9.628037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine</th>\n",
       "      <td>8.370756</td>\n",
       "      <td>7.436642</td>\n",
       "      <td>10.202690</td>\n",
       "      <td>8.181618</td>\n",
       "      <td>8.681155</td>\n",
       "      <td>9.368878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abolition</th>\n",
       "      <td>9.532550</td>\n",
       "      <td>7.737205</td>\n",
       "      <td>11.607673</td>\n",
       "      <td>8.752913</td>\n",
       "      <td>9.936628</td>\n",
       "      <td>9.497723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2114 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0         1          2         3         4         5\n",
       "student            4.461106  5.245509   6.531579  3.803008  4.376983  6.363828\n",
       "learn              4.556132  4.809060   6.977041  3.949124  4.278583  6.672489\n",
       "implicit           6.331229  7.343241   7.000492  6.470834  6.698545  7.979024\n",
       "explicit           5.783002  6.684466   8.166710  6.198750  6.228590  8.303774\n",
       "non                4.376479  5.877950   7.075219  5.137199  5.576512  6.939883\n",
       "...                     ...       ...        ...       ...       ...       ...\n",
       "capture            7.165847  6.914288   9.295683  7.328633  7.827425  8.653174\n",
       "inappropriateness  7.548584  7.927481   8.994511  8.002313  8.295702  9.165384\n",
       "seriousness        7.954154  8.521012   9.016651  8.596704  8.011523  9.628037\n",
       "genuine            8.370756  7.436642  10.202690  8.181618  8.681155  9.368878\n",
       "abolition          9.532550  7.737205  11.607673  8.752913  9.936628  9.497723\n",
       "\n",
       "[2114 rows x 6 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dist = pd.DataFrame(dists).T\n",
    "df_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bd13d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {}\n",
    "for i, l in enumerate(labels):\n",
    "    term = terms.index[i]\n",
    "    if l not in topics.keys():\n",
    "        topics[l] = []\n",
    "    topics[l].append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1475291f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 606, 0: 337, 4: 369, 2: 204, 1: 387, 5: 211}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: len(v) for k, v in topics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "843ccc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Index(['provide', 'strategy', 'identify', 'develop', 'practice', 'promote',\n",
      "       'guide', 'aspect', 'student', 'consider'],\n",
      "      dtype='object')\n",
      "0\n",
      "Index(['enable', 'obtain', 'reflect', 'non', 'select', 'acquire', 'meaningful',\n",
      "       'test', 'employ', 'examination'],\n",
      "      dtype='object')\n",
      "4\n",
      "Index(['society', 'critical', 'knowledge', 'skill', 'implementation', 'change',\n",
      "       'challenge', 'need', 'system', 'individual'],\n",
      "      dtype='object')\n",
      "2\n",
      "Index(['normative', 'competency', 'implication', 'methodological', 'analyse',\n",
      "       'qualitative', 'motivate', 'align', 'transdisciplinary', 'curricular'],\n",
      "      dtype='object')\n",
      "1\n",
      "Index(['argue', 'include', 'examine', 'involve', 'propose', 'carry', 'suggest',\n",
      "       'incorporate', 'conclude', 'build'],\n",
      "      dtype='object')\n",
      "5\n",
      "Index(['germany', 'springer', 'academia', 'poland', 'asu', 'switzerland',\n",
      "       'ict', 'spain', 'taylor', 'central'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for topic_id in topics.keys():\n",
    "    topic_terms = topics[topic_id]\n",
    "    print(topic_id)\n",
    "    print(df_dist.loc[topic_terms][topic_id].sort_values()[:10].index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
